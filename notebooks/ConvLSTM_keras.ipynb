{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.virtualenvs/cv34/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/user/.virtualenvs/cv34/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/user/.virtualenvs/cv34/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/user/.virtualenvs/cv34/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/user/.virtualenvs/cv34/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/user/.virtualenvs/cv34/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/user/.virtualenvs/cv34/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/user/.virtualenvs/cv34/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/user/.virtualenvs/cv34/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/user/.virtualenvs/cv34/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/user/.virtualenvs/cv34/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/user/.virtualenvs/cv34/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D\n",
    "from tensorflow.keras.layers import ConvLSTM2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# We create a layer which take as input movies of shape\n",
    "# (n_frames, width, height, channels) and returns a movie\n",
    "# of identical shape.\n",
    "\n",
    "seq = Sequential()\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   input_shape=(None, 40, 40, 1),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
    "                   padding='same', return_sequences=True))\n",
    "seq.add(BatchNormalization())\n",
    "\n",
    "seq.add(Conv3D(filters=1, kernel_size=(3, 3, 3),\n",
    "               activation='sigmoid',\n",
    "               padding='same', data_format='channels_last'))\n",
    "seq.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
    "\n",
    "\n",
    "# Artificial data generation:\n",
    "# Generate movies with 3 to 7 moving squares inside.\n",
    "# The squares are of shape 1x1 or 2x2 pixels,\n",
    "# which move linearly over time.\n",
    "# For convenience we first create movies with bigger width and height (80x80)\n",
    "# and at the end we select a 40x40 window.\n",
    "\n",
    "def generate_movies(n_samples=1200, n_frames=15):\n",
    "    row = 80\n",
    "    col = 80\n",
    "    noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n",
    "    shifted_movies = np.zeros((n_samples, n_frames, row, col, 1),\n",
    "                              dtype=np.float)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Add 3 to 7 moving squares\n",
    "        n = np.random.randint(3, 8)\n",
    "\n",
    "        for j in range(n):\n",
    "            # Initial position\n",
    "            xstart = np.random.randint(20, 60)\n",
    "            ystart = np.random.randint(20, 60)\n",
    "            # Direction of motion\n",
    "            directionx = np.random.randint(0, 3) - 1\n",
    "            directiony = np.random.randint(0, 3) - 1\n",
    "\n",
    "            # Size of the square\n",
    "            w = np.random.randint(2, 4)\n",
    "\n",
    "            for t in range(n_frames):\n",
    "                x_shift = xstart + directionx * t\n",
    "                y_shift = ystart + directiony * t\n",
    "                noisy_movies[i, t, x_shift - w: x_shift + w,\n",
    "                             y_shift - w: y_shift + w, 0] += 1\n",
    "\n",
    "                # Make it more robust by adding noise.\n",
    "                # The idea is that if during inference,\n",
    "                # the value of the pixel is not exactly one,\n",
    "                # we need to train the network to be robust and still\n",
    "                # consider it as a pixel belonging to a square.\n",
    "                if np.random.randint(0, 2):\n",
    "                    noise_f = (-1)**np.random.randint(0, 2)\n",
    "                    noisy_movies[i, t,\n",
    "                                 x_shift - w - 1: x_shift + w + 1,\n",
    "                                 y_shift - w - 1: y_shift + w + 1,\n",
    "                                 0] += noise_f * 0.1\n",
    "\n",
    "                # Shift the ground truth by 1\n",
    "                x_shift = xstart + directionx * (t + 1)\n",
    "                y_shift = ystart + directiony * (t + 1)\n",
    "                shifted_movies[i, t, x_shift - w: x_shift + w,\n",
    "                               y_shift - w: y_shift + w, 0] += 1\n",
    "\n",
    "    # Cut to a 40x40 window\n",
    "    noisy_movies = noisy_movies[::, ::, 20:60, 20:60, ::]\n",
    "    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n",
    "    noisy_movies[noisy_movies >= 1] = 1\n",
    "    shifted_movies[shifted_movies >= 1] = 1\n",
    "    return noisy_movies, shifted_movies\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 15, 40, 40, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_movies, shifted_movies = generate_movies(n_samples=1200)\n",
    "noisy_movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network\n",
    "\n",
    "seq.fit(noisy_movies[:1000], shifted_movies[:1000], batch_size=10,\n",
    "        epochs=10, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the network on one movie\n",
    "# feed it with the first 7 positions and then\n",
    "# predict the new positions\n",
    "which = 1004\n",
    "track = noisy_movies[which][:7, ::, ::, ::]\n",
    "\n",
    "for j in range(16):\n",
    "    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n",
    "    new = new_pos[::, -1, ::, ::, ::]\n",
    "    track = np.concatenate((track, new), axis=0)\n",
    "\n",
    "\n",
    "# And then compare the predictions\n",
    "# to the ground truth\n",
    "track2 = noisy_movies[which][::, ::, ::, ::]\n",
    "for i in range(15):\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "    ax = fig.add_subplot(121)\n",
    "\n",
    "    if i >= 7:\n",
    "        ax.text(1, 3, 'Predictions !', fontsize=20, color='w')\n",
    "    else:\n",
    "        ax.text(1, 3, 'Initial trajectory', fontsize=20)\n",
    "\n",
    "    toplot = track[i, ::, ::, 0]\n",
    "\n",
    "    plt.imshow(toplot)\n",
    "    ax = fig.add_subplot(122)\n",
    "    plt.text(1, 3, 'Ground truth', fontsize=20)\n",
    "\n",
    "    toplot = track2[i, ::, ::, 0]\n",
    "    if i >= 2:\n",
    "        toplot = shifted_movies[which][i - 1, ::, ::, 0]\n",
    "\n",
    "    plt.imshow(toplot)\n",
    "    plt.savefig('%i_animate.png' % (i + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeGaussian(size, fwhm = 3, center=None):\n",
    "    \"\"\" Make a square gaussian kernel.\n",
    "\n",
    "    size is the length of a side of the square\n",
    "    fwhm is full-width-half-maximum, which\n",
    "    can be thought of as an effective radius.\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.arange(0, size, 1, float)\n",
    "    y = x[:,np.newaxis]\n",
    "\n",
    "    if center is None:\n",
    "        x0 = y0 = size // 2\n",
    "    else:\n",
    "        x0 = center[0]\n",
    "        y0 = center[1]\n",
    "\n",
    "    return np.exp(-4*np.log(2) * ((x-x0)**2 + (y-y0)**2) / fwhm**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = makeGaussian(32, fwhm = 3, center=(16, 16))\n",
    "pred = makeGaussian(32, fwhm = 3, center=(10, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe6263f9748>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADQ9JREFUeJzt3V2sHPV5x/HvE3Ns81YFF+JYxiqE0BfUNgYdOVRBURpKRFElQ1VFcBFxgXqiKkhBSi8sKrVU6gWpCihXVKZYcSsKoQUEilAb10WikSqHAzXG4BYIdRRbfiEiCS6lfn16sWPp2DqzZ312dxb7+X6ko539z8z+H43Ob2dnZvc/kZlIqudjky5A0mQYfqkowy8VZfilogy/VJThl4oy/FJRhl8qyvBLRZ03zMoRcTPwLWAJ8DeZeX+/5ZfGslzOhcN0KamP/+MDjuThGGTZWOzXeyNiCfAmcBOwB3gJuCMz32hb5xdiRX42blxUf5IWti238n6+N1D4h/nYvw54OzPfycwjwBPA+iFeT1KHhgn/auDHc57vadoknQWGOuYfRETMADMAy7lg3N1JGtAwe/69wJo5zy9v2k6RmRszczozp6dYNkR3kkZpmPC/BFwdEVdGxFLgduC50ZQladwW/bE/M49FxN3AP9O71LcpM18fWWWSxmqoY/7MfB54fkS1SOqQ3/CTijL8UlGGXyrK8EtFGX6pKMMvFWX4paIMv1SU4ZeKMvxSUYZfKsrwS0UZfqkowy8VZfilogy/VJThl4oy/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9UlOGXihrqjj0RsRs4BBwHjmXm9CiKkjR+o7hF929n5k9G8DqSOuTHfqmoYcOfwPci4uWImBlFQZK6MezH/hsyc29EfALYEhH/mZkvzl2geVOYAVjOBUN2J2lUhtrzZ+be5vEg8Aywbp5lNmbmdGZOT7FsmO4kjdCiwx8RF0bExSengS8BO0dVmKTxGuZj/0rgmYg4+Tp/n5n/NJKqJI3dosOfme8AnxlhLZI65KU+qSjDLxVl+KWiDL9UlOGXijL8UlGGXyrK8EtFGX6pKMMvFWX4paIMv1SU4ZeKMvxSUYZfKsrwS0UZfqkowy8VZfilogy/VJThl4oy/FJRhl8qyvBLRRl+qagFwx8RmyLiYETsnNO2IiK2RMRbzeMl4y1T0qgNsuf/NnDzaW0bgK2ZeTWwtXku6SyyYPgz80XgvdOa1wObm+nNwK0jrkvSmC32mH9lZu5rpvfTu2OvpLPI0Cf8MjOBbJsfETMRMRsRs0c5PGx3kkZkseE/EBGrAJrHg20LZubGzJzOzOkpli2yO0mjttjwPwfc2UzfCTw7mnIkdWWQS32PA/8O/EpE7ImIu4D7gZsi4i3gd5rnks4i5y20QGbe0TLrxhHXIqlDfsNPKsrwS0UZfqkowy8VZfilohY8268CIkb/mtn6pU99RLjnl4oy/FJRhl8qyvBLRRl+qSjDLxXlpb5zTctluzhvqnWVj114fvvrLeszBsPh9sFZTnzw4bzteexo++t5ebBT7vmlogy/VJThl4oy/FJRhl8qyrP955i2s/pLPvmJ1nU+/LVPts7738va/0UuePdY67zzd+2ft/34/taBnsmjR1rnafTc80tFGX6pKMMvFWX4paIMv1SU4ZeKWvBSX0RsAn4POJiZv9603Qf8IfBus9i9mfn8uIrUafqMudf2I51+l/P++/fb9wGf/Y03W+dte+3TrfOufHr+/pYfOtS6zvGf+6OfLg2y5/82cPM87Q9l5trmz+BLZ5kFw5+ZLwLvdVCLpA4Nc8x/d0TsiIhNEXHJyCqS1InFhv9h4CpgLbAPeKBtwYiYiYjZiJg9SvvgD5K6tajwZ+aBzDyemSeAR4B1fZbdmJnTmTk9RZ9RYSR1alHhj4hVc57eBuwcTTmSujLIpb7HgS8Al0bEHuDPgC9ExFoggd3AV8dYo85Ey5h7/X6d1+9y3hNX/mvrvNv7lLH733553vbl/cYEVKcWDH9m3jFP86NjqEVSh/yGn1SU4ZeKMvxSUYZfKsrwS0U5gOe5puUWWv0G2+z367x+l/P6/qqvrb8+t/hSt9zzS0UZfqkowy8VZfilogy/VJThl4ryUt/ZqM9glic++HDe9rZ750H7YJvQ/us86HM5r09/x1vqAxyks2Pu+aWiDL9UlOGXijL8UlGGXyrKs/3nmDw2/y2vju8/2LpOv1to9R1zr8+PdNrO6rfVp+6555eKMvxSUYZfKsrwS0UZfqkowy8VNcjtutYAfwuspHd7ro2Z+a2IWAF8B7iC3i27vpyZPx1fqRpIy49j8uiR1lWO/3wMl9/8kc5H3iB7/mPANzLzGuB64GsRcQ2wAdiamVcDW5vnks4SC4Y/M/dl5ivN9CFgF7AaWA9sbhbbDNw6riIljd4ZHfNHxBXAtcA2YGVm7mtm7ad3WCDpLDFw+CPiIuAp4J7MfH/uvMxMeucD5ltvJiJmI2L2KI7ZLn1UDBT+iJiiF/zHMvPppvlARKxq5q8C5v3yeGZuzMzpzJyewnuzSx8VC4Y/IgJ4FNiVmQ/OmfUccGczfSfw7OjLkzQug/yq73PAV4DXImJ703YvcD/wZETcBfwI+PJ4StTYeVmupAXDn5nfB6Jl9o2jLUdSV/yGn1SU4ZeKMvxSUYZfKsrwS0UZfqkowy8VZfilogy/VJThl4oy/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9UlOGXijL8UlGGXyrK8EtFGX6pKMMvFWX4paIMv1TUIPfqWxMRL0TEGxHxekR8vWm/LyL2RsT25u+W8ZcraVQGuVffMeAbmflKRFwMvBwRW5p5D2XmX42vPEnjMsi9+vYB+5rpQxGxC1g97sIkjdcZHfNHxBXAtcC2punuiNgREZsi4pIR1yZpjAYOf0RcBDwF3JOZ7wMPA1cBa+l9MnigZb2ZiJiNiNmjHB5ByZJGYaDwR8QUveA/lplPA2Tmgcw8npkngEeAdfOtm5kbM3M6M6enWDaquiUNaZCz/QE8CuzKzAfntK+as9htwM7RlydpXAY52/854CvAaxGxvWm7F7gjItYCCewGvjqWCiWNxSBn+78PxDyznh99OZK64jf8pKIMv1SU4ZeKMvxSUYZfKsrwS0UZfqkowy8VZfilogy/VJThl4oy/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9UlOGXijL8UlGGXyrK8EtFGX6pKMMvFWX4paIGuVff8oj4QUS8GhGvR8SfN+1XRsS2iHg7Ir4TEUvHX66kURlkz38Y+GJmfobe7bhvjojrgW8CD2Xmp4GfAneNr0xJo7Zg+LPnf5qnU81fAl8E/rFp3wzcOpYKJY3FQMf8EbGkuUPvQWAL8EPgZ5l5rFlkD7B6PCVKGoeBwp+ZxzNzLXA5sA741UE7iIiZiJiNiNmjHF5kmZJG7YzO9mfmz4AXgN8CPh4RJ2/xfTmwt2WdjZk5nZnTUywbqlhJozPI2f7LIuLjzfT5wE3ALnpvAn/QLHYn8Oy4ipQ0euctvAirgM0RsYTem8WTmfndiHgDeCIi/gL4D+DRMdYpacQWDH9m7gCunaf9HXrH/5LOQn7DTyrK8EtFGX6pKMMvFWX4paIiM7vrLOJd4EfN00uBn3TWeTvrOJV1nOpsq+OXMvOyQV6w0/Cf0nHEbGZOT6Rz67AO6/Bjv1SV4ZeKmmT4N06w77ms41TWcapzto6JHfNLmiw/9ktFTST8EXFzRPxXM/jnhknU0NSxOyJei4jtETHbYb+bIuJgROyc07YiIrZExFvN4yUTquO+iNjbbJPtEXFLB3WsiYgXIuKNZpDYrzftnW6TPnV0uk06GzQ3Mzv9A5bQGwbsU8BS4FXgmq7raGrZDVw6gX4/D1wH7JzT9pfAhmZ6A/DNCdVxH/DHHW+PVcB1zfTFwJvANV1vkz51dLpNgAAuaqangG3A9cCTwO1N+18DfzRMP5PY868D3s7MdzLzCPAEsH4CdUxMZr4IvHda83p6A6FCRwOittTRuczcl5mvNNOH6A0Ws5qOt0mfOjqVPWMfNHcS4V8N/HjO80kO/pnA9yLi5YiYmVANJ63MzH3N9H5g5QRruTsidjSHBWM//JgrIq6gN37ENia4TU6rAzreJl0Mmlv9hN8NmXkd8LvA1yLi85MuCHrv/PTemCbhYeAqevdo2Ac80FXHEXER8BRwT2a+P3del9tknjo63yY5xKC5g5pE+PcCa+Y8bx38c9wyc2/zeBB4hsmOTHQgIlYBNI8HJ1FEZh5o/vFOAI/Q0TaJiCl6gXssM59umjvfJvPVMalt0vR9xoPmDmoS4X8JuLo5c7kUuB14rusiIuLCiLj45DTwJWBn/7XG6jl6A6HCBAdEPRm2xm10sE0iIuiNAbkrMx+cM6vTbdJWR9fbpLNBc7s6g3na2cxb6J1J/SHwJxOq4VP0rjS8CrzeZR3A4/Q+Ph6ld+x2F/CLwFbgLeBfgBUTquPvgNeAHfTCt6qDOm6g95F+B7C9+bul623Sp45Otwnwm/QGxd1B743mT+f8z/4AeBv4B2DZMP34DT+pqOon/KSyDL9UlOGXijL8UlGGXyrK8EtFGX6pKMMvFfX/pZx7hodFUHMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2, shape=(32,), dtype=int64, numpy=\n",
       "array([15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=10, shape=(), dtype=int64, numpy=10>,\n",
       " <tf.Tensor: id=17, shape=(), dtype=int64, numpy=15>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(pred, axis=1)[0], tf.argmax(pred, axis=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=585, shape=(), dtype=float64, numpy=0.0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = makeGaussian(32, fwhm = 3, center=(16, 16))\n",
    "pred = makeGaussian(32, fwhm = 3, center=(16, 16))\n",
    "\n",
    "K.sum(tf.losses.kullback_leibler_divergence(labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(22.199444, shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe620332048>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = makeGaussian(32, fwhm = 3, center=(16, 16))\n",
    "pred = makeGaussian(32, fwhm = 3, center=(16, 16))\n",
    "#pred = np.ones((32, 32))\n",
    "#pred[pred < 0.01] = 0 \n",
    "#labels = K.zeros((32,32))\n",
    "labels = K.variable(labels > 0.2)\n",
    "pred = K.variable(pred)\n",
    "bce = K.binary_crossentropy(labels, pred)\n",
    "print(K.sum(bce))\n",
    "plt.imshow(bce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1.0):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "def bootstrapped_crossentropy(y_true, y_pred, bootstrap_type='hard', alpha=0.95):\n",
    "    target_tensor = y_true\n",
    "    prediction_tensor = y_pred\n",
    "    _epsilon = tf.convert_to_tensor(K.epsilon(), prediction_tensor.dtype.base_dtype)\n",
    "    prediction_tensor = tf.clip_by_value(prediction_tensor, _epsilon, 1 - _epsilon)\n",
    "    prediction_tensor = tf.math.log(prediction_tensor / (1 - prediction_tensor))\n",
    "\n",
    "    if bootstrap_type == 'soft':\n",
    "        bootstrap_target_tensor = alpha * target_tensor + (1.0 - alpha) * K.sigmoid(prediction_tensor)\n",
    "    else:\n",
    "        bootstrap_target_tensor = alpha * target_tensor + (1.0 - alpha) * K.cast(\n",
    "            K.sigmoid(prediction_tensor) > 0.5, tf.float32)\n",
    "    return K.mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        labels=bootstrap_target_tensor, logits=prediction_tensor))\n",
    "\n",
    "def dice_coef_loss_bce(y_true, y_pred, dice=0.5, bce=0.5, bootstrapping='hard', alpha=1.):\n",
    "    return bootstrapped_crossentropy(y_true, y_pred, bootstrapping, alpha) * bce + dice_coef_loss(y_true, y_pred) * dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.007877e-08, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "labels = makeGaussian(32, fwhm = 3, center=(16, 16))\n",
    "pred = makeGaussian(32, fwhm = 3, center=(16, 16))\n",
    "#pred = np.ones((32, 32))\n",
    "#pred[pred < 0.01] = 0 \n",
    "#labels = K.zeros((32,32))\n",
    "labels = K.variable(labels > 0.2)\n",
    "pred = K.variable(pred > 0.2)\n",
    "bce_dice = dice_coef_loss_bce(labels, pred, dice=0.8, bce=0.2, bootstrapping='soft', alpha=1)\n",
    "print(K.sum(bce_dice))\n",
    "# plt.imshow(bce_dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe6204950b8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pred > 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
